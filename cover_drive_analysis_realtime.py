# -*- coding: utf-8 -*-
"""Untitled112.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aeiLlt3L1Ymex3vRZ0_ZplqFPAo5TCrx
"""

# dependencies
!pip install yt-dlp==2025.8.11 opencv-python==4.10.0.84 mediapipe==0.10.14 numpy==2.0.1 ffmpeg-python
!apt-get update && apt-get install -y ffmpeg





import os
import json
import cv2
import mediapipe as mp
import numpy as np
import yt_dlp
from google.colab import files
from IPython.display import Video, display
from collections import deque

# Constants and Thresholds
VIDEO_URL = "https://youtube.com/shorts/vSX3IRxGnNY"
INPUT_VIDEO_RAW = "/content/input_raw.mp4"
INPUT_VIDEO = "/content/input.mp4"
OUTPUT_DIR = "/content/output"
OUTPUT_VIDEO = os.path.join(OUTPUT_DIR, "annotated_video.mp4")
OUTPUT_VIDEO_TEMP = os.path.join(OUTPUT_DIR, "annotated_video_temp.mp4")
EVAL_FILE = os.path.join(OUTPUT_DIR, "evaluation.json")

# Biomechanical Thresholds
GOOD_ELBOW_ANGLE = 120      # degrees (shoulder-elbow-wrist)
GOOD_SPINE_LEAN = 15        # degrees from vertical
GOOD_HEAD_KNEE_ALIGN = 40   # pixels horizontal distance
GOOD_FOOT_ANGLE = 15        # degrees deviation from perpendicular to crease
MIN_ELBOW_FOLLOW = 140      # minimum elbow angle for good follow-through
ROLLING_WINDOW = 15         # frames for rolling average

# MediaPipe setup
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils
pose = mp_pose.Pose(
    static_image_mode=False,
    model_complexity=2,  # Higher complexity for better accuracy
    enable_segmentation=False,
    min_detection_confidence=0.3,
    min_tracking_confidence=0.3
)

class BiomechanicalAnalyzer:
    def __init__(self, window_size=ROLLING_WINDOW):
        self.window_size = window_size
        self.elbow_angles = deque(maxlen=window_size)
        self.spine_leans = deque(maxlen=window_size)
        self.head_knee_dists = deque(maxlen=window_size)
        self.foot_angles = deque(maxlen=window_size)

        # Full session data
        self.all_elbow_angles = []
        self.all_spine_leans = []
        self.all_head_knee_dists = []
        self.all_foot_angles = []
        self.pose_detection_rate = []

    def calculate_angle(self, a, b, c):
        """Calculate angle between three points (A-B-C)"""
        try:
            ba = a - b
            bc = c - b
            cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))
            cosine_angle = np.clip(cosine_angle, -1.0, 1.0)
            angle = np.arccos(cosine_angle)
            return np.degrees(angle)
        except:
            return None

    def get_landmark_xy(self, landmark, width, height):
        """Extract 2D coordinates from MediaPipe landmark"""
        if landmark.visibility < 0.2 or landmark.presence < 0.2:
            return None
        return np.array([landmark.x * width, landmark.y * height])

    def calculate_spine_lean(self, left_hip, right_hip, left_shoulder, right_shoulder):
        """Calculate spine lean angle from vertical"""
        if any(p is None for p in [left_hip, right_hip, left_shoulder, right_shoulder]):
            return None

        mid_hip = (left_hip + right_hip) / 2
        mid_shoulder = (left_shoulder + right_shoulder) / 2

        # Spine vector (from hip to shoulder)
        spine_vector = mid_shoulder - mid_hip
        # Vertical reference (pointing up)
        vertical_vector = np.array([0, -1])

        # Calculate angle between spine and vertical
        spine_lean = self.calculate_angle(
            mid_hip + vertical_vector,
            mid_hip,
            mid_shoulder
        )
        return spine_lean

    def calculate_foot_direction(self, knee, ankle):
        """Calculate foot direction relative to horizontal (crease direction)"""
        if knee is None or ankle is None:
            return None

        foot_vector = ankle - knee
        # Horizontal reference (along x-axis, representing crease direction)
        horizontal_vector = np.array([1, 0])

        # Calculate angle between foot and horizontal
        foot_angle = self.calculate_angle(
            knee + horizontal_vector,
            knee,
            ankle
        )
        return foot_angle

    def analyze_frame(self, landmarks, width, height):
        """Analyze biomechanics for a single frame"""
        metrics = {}
        feedback = []

        # Extract key landmarks
        head = self.get_landmark_xy(landmarks[mp_pose.PoseLandmark.NOSE], width, height)
        left_shoulder = self.get_landmark_xy(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER], width, height)
        left_elbow = self.get_landmark_xy(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW], width, height)
        left_wrist = self.get_landmark_xy(landmarks[mp_pose.PoseLandmark.LEFT_WRIST], width, height)
        left_hip = self.get_landmark_xy(landmarks[mp_pose.PoseLandmark.LEFT_HIP], width, height)
        left_knee = self.get_landmark_xy(landmarks[mp_pose.PoseLandmark.LEFT_KNEE], width, height)
        left_ankle = self.get_landmark_xy(landmarks[mp_pose.PoseLandmark.LEFT_ANKLE], width, height)
        right_hip = self.get_landmark_xy(landmarks[mp_pose.PoseLandmark.RIGHT_HIP], width, height)
        right_shoulder = self.get_landmark_xy(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER], width, height)

        # 1. Front elbow angle (shoulder–elbow–wrist)
        if all(p is not None for p in [left_shoulder, left_elbow, left_wrist]):
            elbow_angle = self.calculate_angle(left_shoulder, left_elbow, left_wrist)
            if elbow_angle is not None:
                metrics['elbow_angle'] = elbow_angle
                self.elbow_angles.append(elbow_angle)
                self.all_elbow_angles.append(elbow_angle)

                if elbow_angle > GOOD_ELBOW_ANGLE:
                    feedback.append("Good elbow elevation")
                else:
                    feedback.append("Lift elbow higher")

        # 2. Spine lean (hip–shoulder line vs. vertical)
        spine_lean = self.calculate_spine_lean(left_hip, right_hip, left_shoulder, right_shoulder)
        if spine_lean is not None:
            metrics['spine_lean'] = spine_lean
            self.spine_leans.append(spine_lean)
            self.all_spine_leans.append(spine_lean)

            if spine_lean < GOOD_SPINE_LEAN:
                feedback.append("Good spine alignment")
            else:
                feedback.append("Reduce forward lean")

        # 3. Head-over-knee vertical alignment
        if head is not None and left_knee is not None:
            head_knee_dist = abs(head[0] - left_knee[0])  # Horizontal distance
            metrics['head_knee_dist'] = head_knee_dist
            self.head_knee_dists.append(head_knee_dist)
            self.all_head_knee_dists.append(head_knee_dist)

            if head_knee_dist < GOOD_HEAD_KNEE_ALIGN:
                feedback.append("Head over front knee")
            else:
                feedback.append("Head not over front knee")

        # 4. Front foot direction (toe/foot angle vs. crease)
        foot_angle = self.calculate_foot_direction(left_knee, left_ankle)
        if foot_angle is not None:
            # Convert to deviation from perpendicular (90 degrees)
            foot_deviation = abs(foot_angle - 90)
            metrics['foot_angle'] = foot_angle
            metrics['foot_deviation'] = foot_deviation
            self.foot_angles.append(foot_deviation)
            self.all_foot_angles.append(foot_deviation)

            if foot_deviation < GOOD_FOOT_ANGLE:
                feedback.append("Good foot direction")
            else:
                feedback.append("Point foot straighter")

        # Calculate rolling averages for smoother feedback
        rolling_metrics = {}
        if len(self.elbow_angles) > 3:
            rolling_metrics['avg_elbow'] = np.mean(list(self.elbow_angles))
        if len(self.spine_leans) > 3:
            rolling_metrics['avg_spine'] = np.mean(list(self.spine_leans))
        if len(self.head_knee_dists) > 3:
            rolling_metrics['avg_head_knee'] = np.mean(list(self.head_knee_dists))
        if len(self.foot_angles) > 3:
            rolling_metrics['avg_foot'] = np.mean(list(self.foot_angles))

        return metrics, feedback, rolling_metrics

# Initialize analyzer
analyzer = BiomechanicalAnalyzer()

# Download and convert video
if not os.path.exists(INPUT_VIDEO_RAW):
    print("Downloading video...")
    ydl_opts = {
        'format': 'best[ext=mp4]/best',
        'outtmpl': INPUT_VIDEO_RAW,
        'quiet': True,
    }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        ydl.download([VIDEO_URL])
    print(f"Downloaded: {os.path.getsize(INPUT_VIDEO_RAW) / (1024*1024):.2f} MB")

# Convert video to OpenCV-compatible format
print("Converting video for OpenCV compatibility...")
conversion_cmd = f"ffmpeg -y -i {INPUT_VIDEO_RAW} -c:v libx264 -pix_fmt yuv420p -crf 23 -preset fast {INPUT_VIDEO}"
result = os.system(conversion_cmd)

if result != 0:
    print("Trying alternative conversion...")
    alt_cmd = f"ffmpeg -y -i {INPUT_VIDEO_RAW} -vcodec libx264 -acodec aac {INPUT_VIDEO}"
    result = os.system(alt_cmd)
    if result != 0:
        raise ValueError("Video conversion failed")

print(f"Converted: {os.path.getsize(INPUT_VIDEO) / (1024*1024):.2f} MB")

# Verify and get video properties
cap = cv2.VideoCapture(INPUT_VIDEO)
if not cap.isOpened():
    raise ValueError("Cannot open converted video")

fps = cap.get(cv2.CAP_PROP_FPS)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

print(f"Video: {width}x{height}, {fps:.1f} FPS, {frame_count} frames")

# Test frame reading
ret, test_frame = cap.read()
if not ret:
    raise ValueError("Cannot read video frames")
print(f"Frame reading test passed: {test_frame.shape}")
cap.release()

# Setup processing
scale_factor = 0.5
new_width = int(width * scale_factor)
new_height = int(height * scale_factor)

os.makedirs(OUTPUT_DIR, exist_ok=True)

# Initialize video writer
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(OUTPUT_VIDEO_TEMP, fourcc, fps, (new_width, new_height))

if not out.isOpened():
    raise ValueError("Cannot initialize video writer")

# Process video with enhanced biomechanical analysis
print("Starting biomechanical analysis...")
cap = cv2.VideoCapture(INPUT_VIDEO)
frames_processed = 0
frames_written = 0
pose_detected_count = 0

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frames_processed += 1

    if frames_processed % 50 == 0:
        print(f"Progress: {frames_processed}/{frame_count} frames, {pose_detected_count} poses detected")

    try:
        # Resize frame
        frame_resized = cv2.resize(frame, (new_width, new_height))

        # Convert to RGB for MediaPipe
        image_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
        results = pose.process(image_rgb)

        # Add frame info overlay
        cv2.putText(frame_resized, f"Frame: {frames_processed}/{frame_count}",
                   (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

        if results.pose_landmarks:
            pose_detected_count += 1

            # Draw pose skeleton
            mp_drawing.draw_landmarks(
                frame_resized,
                results.pose_landmarks,
                mp_pose.POSE_CONNECTIONS,
                mp_drawing.DrawingSpec(color=(0, 100, 255), thickness=2, circle_radius=3),
                mp_drawing.DrawingSpec(color=(0, 255, 100), thickness=2)
            )

            # Analyze biomechanics
            landmarks = results.pose_landmarks.landmark
            metrics, feedback, rolling_metrics = analyzer.analyze_frame(landmarks, new_width, new_height)

            # Live overlays - Real-time metric readouts
            y_pos = 50
            cv2.putText(frame_resized, "BIOMECHANICS", (10, y_pos),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
            y_pos += 25

            # Display current frame metrics
            for key, value in metrics.items():
                if key != 'foot_deviation':  # Skip derivative metric
                    display_name = key.replace('_', ' ').title()
                    if 'angle' in key:
                        display_text = f"{display_name}: {value:.0f}°"
                    elif 'dist' in key:
                        display_text = f"{display_name}: {value:.0f}px"
                    else:
                        display_text = f"{display_name}: {value:.1f}"

                    cv2.putText(frame_resized, display_text, (10, y_pos),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
                    y_pos += 20

            # Display rolling averages (if enough data)
            if rolling_metrics:
                cv2.putText(frame_resized, "ROLLING AVG", (200, 50),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 200, 0), 2)
                y_pos = 75
                for key, value in rolling_metrics.items():
                    display_name = key.replace('avg_', '').replace('_', ' ').title()
                    cv2.putText(frame_resized, f"{display_name}: {value:.0f}",
                               (200, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 200, 0), 1)
                    y_pos += 20

            # Live feedback cues
            feedback_y = new_height - 120
            for i, fb in enumerate(feedback):
                color = (0, 255, 0) if 'Good' in fb or 'over' in fb else (0, 0, 255)
                cv2.putText(frame_resized, fb, (10, feedback_y + (i * 20)),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)

            # Pose detection indicator
            cv2.putText(frame_resized, "POSE: DETECTED", (new_width - 150, 25),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)
        else:
            # No pose detected
            cv2.putText(frame_resized, "POSE: NOT DETECTED", (new_width - 180, 25),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)

        # Record pose detection rate
        analyzer.pose_detection_rate.append(1 if results.pose_landmarks else 0)

        # Write frame
        out.write(frame_resized)
        frames_written += 1

    except Exception as e:
        print(f"Error processing frame {frames_processed}: {e}")
        continue

# Release resources
cap.release()
out.release()
pose.close()

print(f"\nProcessing Summary:")
print(f"Frames processed: {frames_processed}")
print(f"Frames written: {frames_written}")
print(f"Poses detected: {pose_detected_count} ({pose_detected_count/frames_processed*100:.1f}%)")

# Convert to final format
if os.path.exists(OUTPUT_VIDEO_TEMP) and os.path.getsize(OUTPUT_VIDEO_TEMP) > 0:
    temp_size = os.path.getsize(OUTPUT_VIDEO_TEMP) / (1024 * 1024)
    print(f"Temporary video: {temp_size:.2f} MB")

    print("Converting to final MP4...")
    final_cmd = f"ffmpeg -y -i {OUTPUT_VIDEO_TEMP} -c:v libx264 -pix_fmt yuv420p -movflags +faststart {OUTPUT_VIDEO}"
    result = os.system(final_cmd)

    if result == 0 and os.path.exists(OUTPUT_VIDEO):
        final_size = os.path.getsize(OUTPUT_VIDEO) / (1024 * 1024)
        print(f"Final video: {final_size:.2f} MB")
    else:
        print("Final conversion failed")

# Final Shot Evaluation
def compute_category_score(values, good_threshold, is_lower_better=False, penalty_factor=0.1):
    """Compute score (1-10) based on average deviation from ideal"""
    if not values:
        return 5, "Insufficient data for analysis"

    avg_value = np.mean(values)
    std_value = np.std(values)

    if is_lower_better:
        # For metrics where lower is better (spine lean, head-knee distance, foot deviation)
        deviation = avg_value - good_threshold if avg_value > good_threshold else 0
        consistency_penalty = std_value * penalty_factor
        raw_score = max(1, 10 - (deviation * 0.2) - consistency_penalty)
    else:
        # For metrics where higher is better (elbow angle)
        deviation = good_threshold - avg_value if avg_value < good_threshold else 0
        consistency_penalty = std_value * penalty_factor
        raw_score = max(1, 10 - (deviation * 0.1) - consistency_penalty)

    score = min(10, max(1, int(raw_score)))
    detail = f"Avg: {avg_value:.1f}, Std: {std_value:.1f}"

    return score, detail

print("\nComputing Final Shot Evaluation...")

# Initialize evaluation data
eval_data = {
    "session_summary": {
        "total_frames": frames_processed,
        "pose_detection_rate": f"{pose_detected_count/frames_processed*100:.1f}%" if frames_processed > 0 else "0%",
        "metrics_collected": len(analyzer.all_elbow_angles)
    }
}

# 1. Footwork Analysis
foot_score, foot_detail = compute_category_score(analyzer.all_foot_angles, GOOD_FOOT_ANGLE, is_lower_better=True)
eval_data["footwork"] = {
    "score": foot_score,
    "detail": foot_detail,
    "feedback": [
        "Keep front foot pointing straight down the pitch",
        "Good foot position helps with balance and power transfer" if foot_score >= 7 else "Focus on foot alignment - it affects your entire stance"
    ]
}

# 2. Head Position Analysis
head_score, head_detail = compute_category_score(analyzer.all_head_knee_dists, GOOD_HEAD_KNEE_ALIGN, is_lower_better=True)
eval_data["head_position"] = {
    "score": head_score,
    "detail": head_detail,
    "feedback": [
        "Keep head steady and over front knee throughout the shot",
        "Excellent head position - maintains balance and timing" if head_score >= 7 else "Work on keeping head still and centered over front leg"
    ]
}

# 3. Swing Control Analysis (Elbow Position)
swing_score, swing_detail = compute_category_score(analyzer.all_elbow_angles, GOOD_ELBOW_ANGLE, is_lower_better=False)
eval_data["swing_control"] = {
    "score": swing_score,
    "detail": swing_detail,
    "feedback": [
        "Maintain high front elbow for better bat control",
        "Strong elbow position gives good control" if swing_score >= 7 else "Lift front elbow higher - it's key for shot control"
    ]
}

# 4. Balance Analysis (Spine Alignment)
balance_score, balance_detail = compute_category_score(analyzer.all_spine_leans, GOOD_SPINE_LEAN, is_lower_better=True)
eval_data["balance"] = {
    "score": balance_score,
    "detail": balance_detail,
    "feedback": [
        "Keep spine upright and avoid excessive forward lean",
        "Good balance maintained throughout" if balance_score >= 7 else "Reduce forward lean to improve balance and shot options"
    ]
}

# 5. Follow-through Analysis
if analyzer.all_elbow_angles:
    max_elbow = np.max(analyzer.all_elbow_angles)
    follow_score = min(10, max(1, int((max_elbow - 90) / 10)))  # Scale from 90-180 degrees
    follow_detail = f"Max extension: {max_elbow:.1f}°"
else:
    follow_score = 5
    follow_detail = "No swing data"

eval_data["follow_through"] = {
    "score": follow_score,
    "detail": follow_detail,
    "feedback": [
        "Complete the shot with full arm extension",
        "Excellent follow-through shows good timing" if follow_score >= 7 else "Extend arms more in follow-through for better shot completion"
    ]
}

# Overall assessment
if analyzer.all_elbow_angles:
    overall_score = np.mean([
        eval_data["footwork"]["score"],
        eval_data["head_position"]["score"],
        eval_data["swing_control"]["score"],
        eval_data["balance"]["score"],
        eval_data["follow_through"]["score"]
    ])

    eval_data["overall"] = {
        "score": round(overall_score, 1),
        "grade": "Excellent" if overall_score >= 8 else "Good" if overall_score >= 6 else "Needs Work",
        "key_strengths": [],
        "key_improvements": []
    }

    # Identify strengths and areas for improvement
    for category, data in eval_data.items():
        if category in ["overall", "session_summary"]:
            continue
        if data["score"] >= 7:
            eval_data["overall"]["key_strengths"].append(category.replace('_', ' ').title())
        elif data["score"] <= 5:
            eval_data["overall"]["key_improvements"].append(category.replace('_', ' ').title())

# Save comprehensive evaluation
with open(EVAL_FILE, 'w') as f:
    json.dump(eval_data, f, indent=4)

# Display results
print(f"\nCRICKET BATTING ANALYSIS COMPLETE")
print(f"=" * 50)

if pose_detected_count > 0:
    print(f"Overall Score: {eval_data.get('overall', {}).get('score', 'N/A')}/10")
    print(f"Grade: {eval_data.get('overall', {}).get('grade', 'N/A')}")
    print(f"Poses Analyzed: {pose_detected_count}/{frames_processed} frames")

    print(f"\nDETAILED BREAKDOWN:")
    categories = ["footwork", "head_position", "swing_control", "balance", "follow_through"]
    for category in categories:
        data = eval_data[category]
        print(f"\n{category.replace('_', ' ').upper()}:")
        print(f"  Score: {data['score']}/10 ({data['detail']})")
        for feedback_line in data['feedback']:
            print(f"  • {feedback_line}")

    # Key recommendations
    if eval_data.get("overall", {}).get("key_improvements"):
        print(f"\nPRIORITY IMPROVEMENTS:")
        for improvement in eval_data["overall"]["key_improvements"]:
            print(f"  • {improvement}")

    if eval_data.get("overall", {}).get("key_strengths"):
        print(f"\nSTRENGTHS:")
        for strength in eval_data["overall"]["key_strengths"]:
            print(f"  • {strength}")

else:
    print("No poses detected - ensure person is clearly visible in video")

print(f"\nOutput Files:")
print(f"  Video: {OUTPUT_VIDEO}")
print(f"  Analysis: {EVAL_FILE}")

# Display video if successful
if os.path.exists(OUTPUT_VIDEO) and os.path.getsize(OUTPUT_VIDEO) > 0:
    print("\nANNOTATED VIDEO:")
    display(Video(OUTPUT_VIDEO, width=600))
else:
    print("\nVideo generation failed")









